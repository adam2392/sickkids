{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "split-corrections",
   "metadata": {},
   "source": [
    "# Benchmark Analyses - Surgical Outcome Predictors\n",
    "\n",
    "Using spectral analyses, we might be interested in how the \"distribution\" of a certain frequency band changes as a result of the resection. For example, we may look at the different frequency bands of each channel decomposed using the Morlet wavelet transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "compliant-devil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import os\n",
    "import json\n",
    "import os.path as op\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from pprint import pprint\n",
    "from natsort import natsorted\n",
    "\n",
    "from mne.io import RawArray\n",
    "from mne import create_info\n",
    "from mne_bids import BIDSPath, get_entity_vals, read_raw_bids\n",
    "import mne\n",
    "from mne.time_frequency import read_tfrs\n",
    "\n",
    "mne.utils.use_log_level('error')\n",
    "\n",
    "import ptitprince as pt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "import pingouin as pg\n",
    "import dabest\n",
    "from hyppo.independence import MGC\n",
    "from hyppo.ksample import KSample\n",
    "\n",
    "from eztrack.utils import Normalize\n",
    "from eztrack.io.base import _add_desc_to_bids_fname, concatenate_derivs\n",
    "from eztrack.viz import _load_turbo, generate_heatmap\n",
    "from eztrack.posthoc.hypo import compute_null\n",
    "\n",
    "_load_turbo()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occasional-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "imposed-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "breeding-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_concat_derivs(deriv_path, subject, session, desc, tasks=None):\n",
    "    # get all the subject/sessions in the derivative path\n",
    "    subjects = get_entity_vals(deriv_path, 'subject')\n",
    "    ignore_subjects = [sub for sub in subjects if sub != subject]\n",
    "    sessions = get_entity_vals(deriv_path, 'session', ignore_subjects=ignore_subjects)\n",
    "    ignore_sessions = [ses for ses in sessions if ses != session]\n",
    "\n",
    "    # store all derivatives found in a list\n",
    "    derivs = []\n",
    "    onsets = []\n",
    "    descriptions = []\n",
    "    prevlen = 0\n",
    "    \n",
    "    if session == 'extraoperative':\n",
    "        tasks = ['interictal', 'ictal']\n",
    "        \n",
    "    if tasks is None:\n",
    "        # get all the tasks associated if not passed in\n",
    "        tasks = get_entity_vals(deriv_path, 'task', \n",
    "                            ignore_subjects=ignore_subjects,\n",
    "                            ignore_sessions=ignore_sessions\n",
    "                           )\n",
    "    for task in tasks:\n",
    "        # get all file paths for this subject\n",
    "        search_str = f'*ses-{session}*task-{task}*desc-{desc}*.json'\n",
    "        deriv_fpaths = natsorted(list((deriv_path / f'sub-{subject}').glob(search_str)))\n",
    "\n",
    "#         print(f'Found {len(deriv_fpaths)} derivative file paths')\n",
    "\n",
    "        for idx, deriv_fpath in enumerate(deriv_fpaths):\n",
    "            deriv = read_derivative_npy(deriv_fpath, preload=True, \n",
    "                                        verbose=False)\n",
    "\n",
    "            if 'ch_axis' not in deriv.info:\n",
    "                deriv.info['ch_axis'] = [0]\n",
    "                rowderiv.info['ch_axis'] = [0 ]\n",
    "\n",
    "            # create derivative structure\n",
    "            onsets.append(prevlen + len(deriv))\n",
    "            descriptions.append(f'ses-{session}-task-{task}-run-{idx+1}')\n",
    "            prevlen += len(deriv)\n",
    "    #         if derivative is None:\n",
    "    #             derivative = deriv.copy()\n",
    "    #             derivs.append(deriv.copy())\n",
    "    #         else:\n",
    "                # check that all channel names are ordered\n",
    "    #                 if derivative.ch_names != deriv.ch_names:\n",
    "    #                     deriv.reorder_channels(derivative.ch_names)\n",
    "    #                     rowderiv.reorder_channels(derivative.ch_names)\n",
    "    #                 assert derivative.ch_names == deriv.ch_names\n",
    "    #                 derivative.append(deriv.copy())\n",
    "            derivs.append(deriv.copy())\n",
    "    return derivs, onsets, descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modified-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deriv_list(derivs, rowderivs, derivtype='col',\n",
    "                       baseline_mean=None, baseline_std=None):\n",
    "    derivative = None\n",
    "    new_derivs = []\n",
    "\n",
    "    # loop through each derivative\n",
    "    for deriv, rowderiv in zip(derivs, rowderivs):\n",
    "        deriv.normalize()\n",
    "        rowderiv.normalize()\n",
    "        orig_filenames = deriv._filenames\n",
    "        \n",
    "        coldata = deriv.get_data()\n",
    "        rowdata = rowderiv.get_data()\n",
    "\n",
    "        if derivtype == 'col':\n",
    "            data = coldata.copy()\n",
    "        elif derivtype == 'row':\n",
    "            data = rowdata.copy()\n",
    "        elif derivtype == 'abs':\n",
    "            # combine the data if wanted\n",
    "            data = np.abs(coldata - rowdata)\n",
    "        elif derivtype == 'prod':\n",
    "            data = np.multiply(coldata, rowdata)\n",
    "            \n",
    "        # re-create a new derivative\n",
    "        new_deriv = DerivativeArray(data, info=deriv.info, verbose=False)\n",
    "\n",
    "        if derivative is None:\n",
    "            if baseline_mean is not None:\n",
    "                # subtract baseline vector from each time point\n",
    "                data = data - baseline_mean[:, None]\n",
    "            if baseline_std is not None:\n",
    "                data = data / baseline_std[:, None]\n",
    "            new_deriv = DerivativeArray(data, info=deriv.info, verbose=False)\n",
    "\n",
    "            derivative = new_deriv.copy()\n",
    "        else:\n",
    "            print('Adding new data...')\n",
    "            if not all([ch in deriv.ch_names for ch in derivative.ch_names]):\n",
    "                # get the set difference of channels\n",
    "                add_chs = list(set(derivative.ch_names) - set(deriv.ch_names))\n",
    "                ch_type = derivative.get_channel_types()[0]\n",
    "                info = create_deriv_info(ch_names=add_chs, sfreq=derivative.info['sfreq'], \n",
    "                                         ch_types=ch_type, \n",
    "                                         description=derivative.description,\n",
    "                                        ch_axis=[0])\n",
    "                addderiv = DerivativeArray(np.ones((len(add_chs), len(deriv)))*-1, \n",
    "                                           info=info, verbose=False)\n",
    "\n",
    "                # add derivative chs\n",
    "                new_deriv = new_deriv.add_channels([addderiv])\n",
    "\n",
    "            if derivative.ch_names != new_deriv.ch_names:\n",
    "                # add channels and reorder if necessary\n",
    "                new_deriv.reorder_channels(derivative.ch_names)\n",
    "\n",
    "                nonrz_inds = [idx for idx, ch in enumerate(new_deriv.ch_names) \n",
    "                             if ch not in add_chs]\n",
    "                data = new_deriv.get_data()\n",
    "                info = new_deriv.info\n",
    "                if baseline_mean is not None:\n",
    "                    data[nonrz_inds, :] = data[nonrz_inds, :] - baseline_mean[nonrz_inds, np.newaxis]\n",
    "                if baseline_std is not None:\n",
    "                    data[nonrz_inds, :] = data[nonrz_inds, :] / baseline_std[nonrz_inds, np.newaxis]\n",
    "                \n",
    "                # make sure data that was disconnected is hardcode set to nan\n",
    "                rz_inds = [idx for idx in range(data.shape[0]) if idx not in nonrz_inds]\n",
    "                data[rz_inds, :] = np.nan\n",
    "                \n",
    "                new_deriv = DerivativeArray(data, info=info, verbose=False)\n",
    "            else:\n",
    "                if baseline_mean is not None:\n",
    "                    # subtract baseline vector from each time point\n",
    "                    data = data - baseline_mean[:, None]\n",
    "                if baseline_std is not None:\n",
    "                    data = data / baseline_std[:, None]\n",
    "\n",
    "                new_deriv = DerivativeArray(data, info=deriv.info, verbose=False)\n",
    "            derivative.append(new_deriv) \n",
    "            \n",
    "        # make sure filenames persist\n",
    "        new_deriv._filenames = orig_filenames\n",
    "        new_derivs.append(new_deriv)\n",
    "    return new_derivs                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "furnished-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_block_bootstrap_stats(pre_deriv, post_deriv, subject, df_summ=None, threshold=None):\n",
    "    # compute effect size difference with sub-sampling\n",
    "    pre_blocks = pre_deriv.subsample_blocks()\n",
    "    post_blocks = post_deriv.subsample_blocks()\n",
    "\n",
    "    cohensd = []\n",
    "    stats = []\n",
    "    pvals = []\n",
    "\n",
    "    for preb, postb in zip(pre_blocks, post_blocks):\n",
    "        if threshold is not None:\n",
    "            preb[np.abs(preb) < threshold] = np.nan\n",
    "            postb[np.abs(postb) < threshold] = np.nan\n",
    "\n",
    "        # drop any nans\n",
    "        preb = preb[~np.isnan(preb)]\n",
    "        postb = postb[~np.isnan(postb)]\n",
    "\n",
    "        stat, pvalue = KSample(\"Dcorr\").test(preb, postb)\n",
    "        stats.append(stat)\n",
    "        pvals.append(pvalue)\n",
    "\n",
    "        es = pg.compute_effsize(preb, postb, \n",
    "                                paired=False, eftype='cohen')\n",
    "\n",
    "        cohensd.append(es)\n",
    "        \n",
    "        if df_summ is not None:\n",
    "            df_summ.append([subject, es, stat, pvalue])\n",
    "    return cohensd, stats, pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-texas",
   "metadata": {},
   "source": [
    "# Define Paths and Parameters for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "greater-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to BIDS dataset / derivatives\n",
    "root = Path('/Users/adam2392/OneDrive - Johns Hopkins/sickkids/')\n",
    "deriv_root = root / 'derivatives'\n",
    "\n",
    "# derivative experiment markers\n",
    "reference = 'average'\n",
    "deriv_chain = Path('tfr') / reference\n",
    "deriv_path = deriv_root / deriv_chain\n",
    "\n",
    "# where to save the data\n",
    "figures_path = deriv_root / 'figures'\n",
    "\n",
    "# all session to analyze\n",
    "sessions = ['extraoperative', 'preresection', \n",
    "            'intraresection', 'postresection']\n",
    "\n",
    "# the derivative ``desc`` entity description\n",
    "desc = 'gamma'  # which frequency band\n",
    "\n",
    "threshold = None\n",
    "baseline = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-ceremony",
   "metadata": {},
   "source": [
    "# Visualize Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "minimal-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adam2392/OneDrive - Johns Hopkins/sickkids/derivatives/tfr/average\n"
     ]
    }
   ],
   "source": [
    "print(deriv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "therapeutic-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AverageTFR | time : [0.000000, 320.123120], freq : [30.000000, 90.000000], nave : 1, channels : 98, ~490.7 MB>\n"
     ]
    }
   ],
   "source": [
    "subject= 'E1'\n",
    "session = 'preresection'\n",
    "task = 'pre'\n",
    "\n",
    "# get all file paths for this subject\n",
    "search_str = f'sub-{subject}_ses-{session}*task-{task}*desc-{desc}*.h5'\n",
    "\n",
    "deriv_fpaths = natsorted(list(deriv_path.rglob(search_str)))\n",
    "\n",
    "for deriv_fpath in deriv_fpaths:\n",
    "    power = read_tfrs(deriv_fpath)[0]\n",
    "    \n",
    "    print(power)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "latin-placement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m             display(\n\u001b[1;32m     40\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             )\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         ticksLight = _is_light([label.get_color()\n\u001b[0m\u001b[1;32m    179\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    179\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                                 for label in axis.get_ticklabels()])\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mticksLight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;31m# there are one or more tick labels, all with the same lightness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_ticklabels\u001b[0;34m(self, minor, which)\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklabels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;34m\"\"\"Return this Axis' major tick labels, as a list of `~.text.Text`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m         \u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0mlabels1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \u001b[0;34mr\"\"\"Return the list of major `.Tick`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumticks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m             \u001b[0mnumticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;34m\"\"\"Return this Axis' major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0;34m\"\"\"Return the locations of the ticks.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sickkids/.venv/lib/python3.8/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m             \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         \u001b[0mlog_vmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2482\u001b[0m         \u001b[0mlog_vmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(\n",
    "#     Normalize().compute_fragilitymetric(\n",
    "    10*np.log10(power.data.mean(axis=1)), ax=ax,\n",
    "#     invert=True), \n",
    "            cmap='viridis', yticklabels=power.ch_names)\n",
    "ax.set(\n",
    "    yscale='log',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-baltimore",
   "metadata": {},
   "source": [
    "# Initialize dataframe for plotting over all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "authentic-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the dataframe summary\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-mattress",
   "metadata": {},
   "source": [
    "# Load data for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "final-province",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All subjects analyzed are: ['E1', 'E3', 'E4', 'E5', 'E6', 'E7']\n"
     ]
    }
   ],
   "source": [
    "# get all subjects analyze\n",
    "subjects = get_entity_vals(deriv_path, 'subject')\n",
    "\n",
    "print(f'All subjects analyzed are: {subjects}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "revised-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurename = 'Col Fragility'\n",
    "# featurename = 'Row Fragility'\n",
    "# featurename = 'Absolute Fragility'\n",
    "\n",
    "# cbarlabel = 'Absolute Diff Fragility'\n",
    "cbarlabel = 'Col Fragility'\n",
    "# cbarlabel = 'Row Fragility'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "handed-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1\n",
      "Sessions in the deriv path ['extraoperative', 'preresection', 'intraresection', 'postresection']\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "9\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "(98, 1279) (98, 120)\n",
      "E3\n",
      "Sessions in the deriv path ['extraoperative', 'preresection', 'intraresection', 'postresection']\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "8\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "(83, 485) (83, 282)\n",
      "E4\n",
      "Sessions in the deriv path ['extraoperative', 'preresection', 'intraresection', 'postresection']\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "7\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "(53, 446) (53, 481)\n",
      "E5\n",
      "Sessions in the deriv path ['extraoperative', 'preresection', 'intraresection', 'postresection']\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "5\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "Adding new data...\n",
      "(58, 483) (58, 372)\n",
      "E6\n",
      "Sessions in the deriv path ['extraoperative', 'preresection', 'intraresection', 'postresection']\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "2\n",
      "Adding new data...\n",
      "(72, 7229) (72, 826)\n",
      "E7\n",
      "Sessions in the deriv path ['extraoperative', 'preresection', 'intraresection', 'postresection']\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "extraoperative\n",
      "preresection\n",
      "intraresection\n",
      "postresection\n",
      "2\n",
      "Adding new data...\n",
      "(111, 606) (111, 654)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>es</th>\n",
       "      <th>stat</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E7</td>\n",
       "      <td>-0.066054</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>9.107672e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E7</td>\n",
       "      <td>0.329984</td>\n",
       "      <td>0.023254</td>\n",
       "      <td>5.226604e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E7</td>\n",
       "      <td>0.291601</td>\n",
       "      <td>0.019912</td>\n",
       "      <td>1.156708e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E7</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>1.004537e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E7</td>\n",
       "      <td>0.263963</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>1.046223e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject        es      stat          pval\n",
       "0      E7 -0.066054  0.005525  9.107672e-04\n",
       "1      E7  0.329984  0.023254  5.226604e-11\n",
       "2      E7  0.291601  0.019912  1.156708e-09\n",
       "3      E7  0.129869  0.003109  1.004537e-02\n",
       "4      E7  0.263963  0.017543  1.046223e-08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 4) (100, 4)\n"
     ]
    }
   ],
   "source": [
    "subj_derivlists = dict()\n",
    "\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "    # get list of sessions for subject\n",
    "    ignore_subjects = [sub for sub in subjects if sub != subject]\n",
    "#     sessions = get_entity_vals(deriv_path, 'session', ignore_subjects=ignore_subjects)\n",
    "    sessions = ['extraoperative', 'preresection', 'intraresection', 'postresection']\n",
    "    print(f'Sessions in the deriv path {sessions}')\n",
    "    \n",
    "    # compute the channel's mean row perturbation values during interictal awake periods\n",
    "    # as a baseline\n",
    "    mean_vec, std_vec = compute_baseline(subject, deriv_root, deriv_chain,\n",
    "                                     task='interictalawake', \n",
    "                                         desc='rowperturbmatrix')\n",
    "\n",
    "    # load all the column perturbation derivatives\n",
    "    derivs = []\n",
    "    onsets = []\n",
    "    descriptions = []\n",
    "    \n",
    "    # keep track of data frame summary statistics\n",
    "    df_summ = []\n",
    "\n",
    "    for session in sessions:\n",
    "        print(session)\n",
    "        derivs_, onsets_, descrips_ = load_concat_derivs(deriv_path, subject, session, \n",
    "                                    desc='perturbmatrix')\n",
    "        derivs.extend(derivs_)\n",
    "        onsets.extend(onsets_)\n",
    "        descriptions.extend(descrips_)\n",
    "    \n",
    "    # load all the row perturbation derivatives\n",
    "    rowderivs = []\n",
    "    for session in sessions:\n",
    "        print(session)\n",
    "        derivs_, _, _ = load_concat_derivs(deriv_path, subject, session, \n",
    "                                    desc='rowperturbmatrix')\n",
    "        rowderivs.extend(derivs_)\n",
    "    print(len(rowderivs))\n",
    "    \n",
    "    # create list of all the onset times \n",
    "    onsets = []\n",
    "    prevonset = 0\n",
    "    for deriv in derivs:\n",
    "        onsets.append(len(deriv) + prevonset)\n",
    "        prevonset += len(deriv)\n",
    "        \n",
    "    # read in the resected channels for the dataset\n",
    "    bids_path = BIDSPath(subject=subject, root=root,\n",
    "                     suffix='channels', extension='.tsv')\n",
    "    ch_fpaths = bids_path.match()\n",
    "\n",
    "    # read in sidecar channels.tsv\n",
    "    channels_pd = pd.read_csv(ch_fpaths[0], sep='\\t')\n",
    "    description_chs = pd.Series(channels_pd.description.values, index=channels_pd.name).to_dict()\n",
    "    resected_chs = [ch for ch, description in description_chs.items() if description == 'resected']\n",
    "    resected_inds = [idx for idx, ch in enumerate(deriv.ch_names) if ch in resected_chs]\n",
    "    nrz_inds = [idx for idx in range(len(deriv.ch_names)) if idx not in resected_inds]\n",
    "    \n",
    "    # generate concatenated list of derivatives\n",
    "    if baseline:\n",
    "        baseline_kwargs=dict(baseline_mean=mean_vec,\n",
    "                                   baseline_std=std_vec\n",
    "                            )\n",
    "    else:\n",
    "        baseline_kwargs = dict()\n",
    "    derivlist = generate_deriv_list(derivs.copy(), rowderivs.copy(), \n",
    "                                    derivtype=derivtype,\n",
    "                                   **baseline_kwargs\n",
    "                                   )\n",
    "    \n",
    "    # only get the pre/post resection data\n",
    "    pre_deriv = [deriv for deriv in derivlist if 'task-pre' in deriv.filenames[0]][0]\n",
    "    post_deriv = [deriv for deriv in derivlist if 'task-post' in deriv.filenames[0]][0]\n",
    "\n",
    "    pre_data = pre_deriv.get_data()\n",
    "    post_data = post_deriv.get_data()\n",
    "    print(pre_data.shape, post_data.shape)\n",
    "    \n",
    "    subj_derivlists[subject] = derivlist\n",
    "    \n",
    "    # compute block-bootstrap statistics\n",
    "    cohensd, stats, pvals = compute_block_bootstrap_stats(pre_deriv, post_deriv, subject=subject,\n",
    "                                                          df_summ=df_summ, threshold=threshold)\n",
    "    \n",
    "    # create \n",
    "    subj_df = pd.DataFrame(df_summ, columns=['subject', 'es', 'stat', 'pval'])\n",
    "    if df.empty:\n",
    "        df = subj_df\n",
    "    else:\n",
    "        df = pd.concat((df, subj_df), axis=0)\n",
    "    \n",
    "display(subj_df.head())\n",
    "print(df.shape, subj_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sickkids",
   "language": "python",
   "name": "sickkids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
